<!DOCTYPE html>
<html lang=zh>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="Kaggle《房价预测》kernel">
<meta property="og:type" content="article">
<meta property="og:title" content="Kaggle机器学习实战（3）——房价预测（下）">
<meta property="og:url" content="https://ster.im/kaggle_03/index.html">
<meta property="og:site_name" content="Rarit7&#39;s Blog">
<meta property="og:description" content="Kaggle《房价预测》kernel">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2018-04-01T07:30:20.000Z">
<meta property="article:modified_time" content="2018-12-23T10:14:55.557Z">
<meta property="article:author" content="Rarit7">
<meta property="article:tag" content="Kaggle">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="集成学习">
<meta property="article:tag" content="Stacking">
<meta name="twitter:card" content="summary">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon-192x192.png">
        
      
    
    <!-- title -->
    <title>Kaggle机器学习实战（3）——房价预测（下）</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({
			tex2jax: {
			  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			  inlineMath: [['$','$']]
			}
		  });
		</script>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
	
<meta name="generator" content="Hexo 5.4.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" "Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">首页</a></li>
         
          <li><a href="/about/">关于</a></li>
         
          <li><a href="/archives/">归档</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="上一篇 " href="/ng_01/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="下一篇 " href="/kaggle_02/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="返回顶部 " href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="分享文章 " href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">上一篇</span>
      <span id="i-next" class="info" style="display:none;">下一篇</span>
      <span id="i-top" class="info" style="display:none;">返回顶部</span>
      <span id="i-share" class="info" style="display:none;">分享文章</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://ster.im/kaggle_03/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://ster.im/kaggle_03/&text=Kaggle机器学习实战（3）——房价预测（下）"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://ster.im/kaggle_03/&title=Kaggle机器学习实战（3）——房价预测（下）"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://ster.im/kaggle_03/&is_video=false&description=Kaggle机器学习实战（3）——房价预测（下）"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Kaggle机器学习实战（3）——房价预测（下）&body=Check out this article: https://ster.im/kaggle_03/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://ster.im/kaggle_03/&title=Kaggle机器学习实战（3）——房价预测（下）"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://ster.im/kaggle_03/&title=Kaggle机器学习实战（3）——房价预测（下）"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://ster.im/kaggle_03/&title=Kaggle机器学习实战（3）——房价预测（下）"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://ster.im/kaggle_03/&title=Kaggle机器学习实战（3）——房价预测（下）"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://ster.im/kaggle_03/&name=Kaggle机器学习实战（3）——房价预测（下）&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://ster.im/kaggle_03/&t=Kaggle机器学习实战（3）——房价预测（下）"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="toc-number">1.</span> <span class="toc-text">导入数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">2.</span> <span class="toc-text">数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A6%BB%E7%BE%A4%E5%80%BC"><span class="toc-number">2.1.</span> <span class="toc-text">离群值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87%E5%8F%98%E9%87%8F"><span class="toc-number">2.2.</span> <span class="toc-text">目标变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E6%80%A7"><span class="toc-number">2.3.</span> <span class="toc-text">相关性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%BA%E5%A4%B1%E5%80%BC"><span class="toc-number">2.4.</span> <span class="toc-text">缺失值</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="toc-number">3.</span> <span class="toc-text">特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E5%80%BC%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BA%E6%A0%87%E7%A7%B0%E5%9E%8B"><span class="toc-number">3.1.</span> <span class="toc-text">数值型转换为标称型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E5%BA%8F%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BA%E6%95%B0%E5%80%BC%E5%9E%8B"><span class="toc-number">3.2.</span> <span class="toc-text">定序型转换为数值型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E9%80%A0%E6%96%B0%E5%8F%98%E9%87%8F"><span class="toc-number">3.3.</span> <span class="toc-text">创造新变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E6%80%81%E5%8C%96%EF%BC%9Abox-cox%E5%8F%98%E6%8D%A2"><span class="toc-number">3.4.</span> <span class="toc-text">正态化：box-cox变换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E5%8F%98%E9%87%8F"><span class="toc-number">3.5.</span> <span class="toc-text">虚拟变量</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%B5%8B%E8%AF%95"><span class="toc-number">4.</span> <span class="toc-text">训练模型与测试</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95"><span class="toc-number">4.1.</span> <span class="toc-text">定义模型评估方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.2.</span> <span class="toc-text">基础模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E6%88%90%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.3.</span> <span class="toc-text">集成模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E9%9B%86%E6%88%90%E6%A8%A1%E5%9E%8B%EF%BC%9A%E5%8F%96%E5%90%84%E4%B8%AA%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9D%87%E5%80%BC"><span class="toc-number">4.3.1.</span> <span class="toc-text">最简单的集成模型：取各个基础模型的均值</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9B%E9%98%B6%EF%BC%9AStacking%E9%9B%86%E6%88%90%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.3.2.</span> <span class="toc-text">进阶：Stacking集成模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E6%88%90Stacking%E3%80%81XGBoost%E5%92%8CLightGBM"><span class="toc-number">4.3.3.</span> <span class="toc-text">集成Stacking、XGBoost和LightGBM</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">5.</span> <span class="toc-text">总结</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Kaggle机器学习实战（3）——房价预测（下）
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Rarit7</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2018-04-01T07:30:20.000Z" itemprop="datePublished">2018-04-01</time>
        
      
    </div>


      
    <div class="article-category">
        <i class="fas fa-archive"></i>
        <a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link-link" href="/tags/Kaggle/" rel="tag">Kaggle</a>, <a class="tag-link-link" href="/tags/Python/" rel="tag">Python</a>, <a class="tag-link-link" href="/tags/Stacking/" rel="tag">Stacking</a>, <a class="tag-link-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a>, <a class="tag-link-link" href="/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" rel="tag">集成学习</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <p>这篇文章翻译自<a target="_blank" rel="noopener" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques">kaggle房价预测</a>上点赞数第二的<a target="_blank" rel="noopener" href="https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard">kernel</a>，该kernel涵盖了从数据预处理到最终建模的完整过程。</p>
<h2 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调包</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">color = sns.color_palette()</span><br><span class="line">sns.set_style(<span class="string">&#x27;darkgrid&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm, skew</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入数据</span></span><br><span class="line">train = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">test = pd.read_csv(<span class="string">&#x27;test.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 展示训练数据的前五行</span></span><br><span class="line">train.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 展示测试数据的前五行</span></span><br><span class="line">test.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 把“Id”这一列从数据集中单独挑出，便于操作</span></span><br><span class="line">train_ID = train[<span class="string">&#x27;Id&#x27;</span>]</span><br><span class="line">train.drop(<span class="string">&quot;Id&quot;</span>, axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">test_ID = test[<span class="string">&#x27;Id&#x27;</span>]</span><br><span class="line">test.drop(<span class="string">&quot;Id&quot;</span>, axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h3 id="离群值"><a href="#离群值" class="headerlink" title="离群值"></a>离群值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制面积与房价的散点图</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(x = train[<span class="string">&#x27;GrLivArea&#x27;</span>], y = train[<span class="string">&#x27;SalePrice&#x27;</span>])</span><br><span class="line">plt.ylabel(<span class="string">&#x27;SalePrice&#x27;</span>, fontsize=<span class="number">13</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;GrLivArea&#x27;</span>, fontsize=<span class="number">13</span>)</span><br></pre></td></tr></table></figure>

<p>从图中可以明显的看出：有两个具有巨大面积的房屋的房价显然过低，因此可以安全地删除它们。<strong>注意</strong>：虽然训练数据中还有其他的离群值可以删除，但无法保证测试数据集中也有离群值，若删除训练样本中的大量离群值会影响测试集上的精度。因此只删除了两个，以使模型更健壮。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除这两个离群值</span></span><br><span class="line">train = train.drop(train[(train[<span class="string">&#x27;GrLivArea&#x27;</span>]&gt;<span class="number">4000</span>) &amp; (train[<span class="string">&#x27;SalePrice&#x27;</span>]&lt;<span class="number">300000</span>)].index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重绘图以查看是否剔除离群值</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(x = train[<span class="string">&#x27;GrLivArea&#x27;</span>], y = train[<span class="string">&#x27;SalePrice&#x27;</span>])</span><br><span class="line">plt.ylabel(<span class="string">&#x27;SalePrice&#x27;</span>, fontsize=<span class="number">13</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;GrLivArea&#x27;</span>, fontsize=<span class="number">13</span>)</span><br></pre></td></tr></table></figure>

<h3 id="目标变量"><a href="#目标变量" class="headerlink" title="目标变量"></a>目标变量</h3><p>Y——房价（<code>SalePrice</code>）是我们需要预测的目标变量。首先要查看它是否满足正态分布。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制Y的概率分布图</span></span><br><span class="line">sns.distplot(train[<span class="string">&#x27;SalePrice&#x27;</span>], fit=norm);</span><br><span class="line">plt.legend([<span class="string">&#x27;Normal dist&#x27;</span>], loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;SalePrice distribution&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取Y的正态分布参数</span></span><br><span class="line">(mu, sigma) = norm.fit(train[<span class="string">&#x27;SalePrice&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n mu = &#123;:.2f&#125; and sigma = &#123;:.2f&#125;\n&#x27;</span>.<span class="built_in">format</span>(mu, sigma))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制QQ-plot图</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(train[<span class="string">&#x27;SalePrice&#x27;</span>], plot=plt)</span><br></pre></td></tr></table></figure>

<p><strong>输出</strong>：mu = 12.02 and sigma = 0.40</p>
<p>可见目标变量Y呈现一种偏态分布，需要将其转换为正态分布以便运用线性回归模型。这里运用了<code>log1p</code>函数，返回的是$\log(1+x)$。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 正态化Y</span></span><br><span class="line">train[<span class="string">&#x27;SalePrice&#x27;</span>] = np.log1p(train[<span class="string">&#x27;SalePrice&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制分布图检查新的分布</span></span><br><span class="line">sns.distplot(train[<span class="string">&#x27;SalePrice&#x27;</span>], fit=norm);</span><br><span class="line">plt.legend([<span class="string">&#x27;Normal dist&#x27;</span>], loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;SalePrice distribution&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取新的正态分布参数</span></span><br><span class="line">(mu, sigma) = norm.fit(train[<span class="string">&#x27;SalePrice&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n mu = &#123;:.2f&#125; and sigma = &#123;:.2f&#125;\n&#x27;</span>.<span class="built_in">format</span>(mu, sigma))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制QQ-plot图</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(train[<span class="string">&#x27;SalePrice&#x27;</span>], plot=plt)</span><br></pre></td></tr></table></figure>

<h3 id="相关性"><a href="#相关性" class="headerlink" title="相关性"></a>相关性</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用热图展示各个变量与Y的相关性</span></span><br><span class="line">corrmat = train.corr()</span><br><span class="line">plt.subplots(figsize=(<span class="number">12</span>,<span class="number">9</span>))</span><br><span class="line">sns.heatmap(corrmat, vmax=<span class="number">0.9</span>, square=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h3 id="缺失值"><a href="#缺失值" class="headerlink" title="缺失值"></a>缺失值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先把训练集和测试集合并起来并丢弃Y，以便处理缺失值</span></span><br><span class="line">ntrain = train.shape[<span class="number">0</span>] <span class="comment"># 训练集数目</span></span><br><span class="line">ntest = test.shape[<span class="number">0</span>] <span class="comment"># 测试集数目</span></span><br><span class="line">y_train = train.SalePrice.values <span class="comment"># 训练集的Y</span></span><br><span class="line">all_data = pd.concat((train, test)).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">all_data.drop([<span class="string">&#x27;SalePrice&#x27;</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;all_data size is : &#123;&#125;&quot;</span>.<span class="built_in">format</span>(all_data.shape))</span><br></pre></td></tr></table></figure>

<p><strong>输出</strong>：all_data size is : (2917, 79)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看缺失值情况</span></span><br><span class="line">all_data_na = (all_data.isnull().<span class="built_in">sum</span>() / <span class="built_in">len</span>(all_data)) * <span class="number">100</span></span><br><span class="line">all_data_na = all_data_na.drop(all_data_na[all_data_na == <span class="number">0</span>].index).sort_values(ascending=<span class="literal">False</span>)[:<span class="number">30</span>]</span><br><span class="line">missing_data = pd.DataFrame(&#123;<span class="string">&#x27;Missing Ratio&#x27;</span> :all_data_na&#125;)</span><br><span class="line">missing_data.head(<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制缺失值的柱状图</span></span><br><span class="line">f, ax = plt.subplots(figsize=(<span class="number">15</span>,<span class="number">12</span>))</span><br><span class="line">plt.xticks(rotation=<span class="string">&#x27;90&#x27;</span>)</span><br><span class="line">sns.barplot(x=all_data_na.index, y=all_data_na)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Features&#x27;</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Percent of missing values&#x27;</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Percent missing data by feature&#x27;</span>, fontsize=<span class="number">15</span>)</span><br></pre></td></tr></table></figure>

<p>参照<a target="_blank" rel="noopener" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data">数据下载页</a>给出的各个变量的解释（data_description.txt），逐一补充缺失值。</p>
<ul>
<li><code>PoolQC</code>, <code>MiscFeature</code>, <code>Alley</code>, <code>Fence</code>, <code>FireplaceQu</code>：这些变量里的空值代表样本房屋不包含泳池、篱笆等设施，因此用<code>None</code>来填充。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">all_data[<span class="string">&quot;PoolQC&quot;</span>] = all_data[<span class="string">&quot;PoolQC&quot;</span>].fillna(<span class="string">&quot;None&quot;</span>)</span><br><span class="line">all_data[<span class="string">&quot;MiscFeature&quot;</span>] = all_data[<span class="string">&quot;MiscFeature&quot;</span>].fillna(<span class="string">&quot;None&quot;</span>)</span><br><span class="line">all_data[<span class="string">&quot;Alley&quot;</span>] = all_data[<span class="string">&quot;Alley&quot;</span>].fillna(<span class="string">&quot;None&quot;</span>)</span><br><span class="line">all_data[<span class="string">&quot;Fence&quot;</span>] = all_data[<span class="string">&quot;Fence&quot;</span>].fillna(<span class="string">&quot;None&quot;</span>)</span><br><span class="line">all_data[<span class="string">&quot;FireplaceQu&quot;</span>] = all_data[<span class="string">&quot;FireplaceQu&quot;</span>].fillna(<span class="string">&quot;None&quot;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>LotFrontage</code>：与街道相连的房产的面积，可以用同一个小区内其他样本该项的中位数来补全。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_data[<span class="string">&quot;LotFrontage&quot;</span>] = all_data.groupby(<span class="string">&quot;Neighborhood&quot;</span>)[<span class="string">&quot;LotFrontage&quot;</span>].transform(<span class="keyword">lambda</span> x: x.fillna(x.median()))</span><br></pre></td></tr></table></figure>

<ul>
<li><code>GarageType</code>, <code>GarageFinish</code>, <code>GarageQual</code>, <code>GarageCond</code>：车库系列变量1，为标称型，用<code>None</code>来填充。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> (<span class="string">&#x27;GarageType&#x27;</span>, <span class="string">&#x27;GarageFinish&#x27;</span>, <span class="string">&#x27;GarageQual&#x27;</span>, <span class="string">&#x27;GarageCond&#x27;</span>):</span><br><span class="line">    all_data[col] = all_data[col].fillna(<span class="string">&#x27;None&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>GarageYrBlt</code>, <code>GarageArea</code>, <code>GarageCars</code>：车库系列变量2，为数值型，用0来填充。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> (<span class="string">&#x27;GarageYrBlt&#x27;</span>, <span class="string">&#x27;GarageArea&#x27;</span>, <span class="string">&#x27;GarageCars&#x27;</span>):</span><br><span class="line">    all_data[col] = all_data[col].fillna(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>BsmtFinSF1</code>, <code>BsmtFinSF2</code>, <code>BsmtUnfSF</code>, <code>TotalBsmtSF</code>, <code>BsmtFullBath</code>, <code>BsmtHalfBath</code>：地下室系列变量1，为数值型，用0来填充。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> (<span class="string">&#x27;BsmtFinSF1&#x27;</span>, <span class="string">&#x27;BsmtFinSF2&#x27;</span>, <span class="string">&#x27;BsmtUnfSF&#x27;</span>,<span class="string">&#x27;TotalBsmtSF&#x27;</span>, <span class="string">&#x27;BsmtFullBath&#x27;</span>, <span class="string">&#x27;BsmtHalfBath&#x27;</span>):</span><br><span class="line">    all_data[col] = all_data[col].fillna(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>BsmtQual</code>, <code>BsmtCond</code>, <code>BsmtExposure</code>, <code>BsmtFinType1</code>, <code>BsmtFinType2</code>：地下室系列变量2，为标称型，用<code>None</code>来填充。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> (<span class="string">&#x27;BsmtQual&#x27;</span>, <span class="string">&#x27;BsmtCond&#x27;</span>, <span class="string">&#x27;BsmtExposure&#x27;</span>, <span class="string">&#x27;BsmtFinType1&#x27;</span>, <span class="string">&#x27;BsmtFinType2&#x27;</span>):</span><br><span class="line">    all_data[col] = all_data[col].fillna(<span class="string">&#x27;None&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>MasVnrArea</code>, <code>MasVnrType</code>：空值代表样本房屋不包含砖石贴面墙，因此分别用0和<code>None</code>来填充。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_data[<span class="string">&quot;MasVnrType&quot;</span>] = all_data[<span class="string">&quot;MasVnrType&quot;</span>].fillna(<span class="string">&quot;None&quot;</span>)</span><br><span class="line">all_data[<span class="string">&quot;MasVnrArea&quot;</span>] = all_data[<span class="string">&quot;MasVnrArea&quot;</span>].fillna(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>MSZoning</code>, <code>Electrical</code>, <code>KitchenQual</code>, <code>Exterior1st</code>, <code>Exterior2nd</code>, <code>SaleType</code>：因为这些变量中仅有个别缺失值，可采用众数填充。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">all_data[<span class="string">&#x27;MSZoning&#x27;</span>] = all_data[<span class="string">&#x27;MSZoning&#x27;</span>].fillna(all_data[<span class="string">&#x27;MSZoning&#x27;</span>].mode()[<span class="number">0</span>])</span><br><span class="line">all_data[<span class="string">&#x27;Electrical&#x27;</span>] = all_data[<span class="string">&#x27;Electrical&#x27;</span>].fillna(all_data[<span class="string">&#x27;Electrical&#x27;</span>].mode()[<span class="number">0</span>])</span><br><span class="line">all_data[<span class="string">&#x27;KitchenQual&#x27;</span>] = all_data[<span class="string">&#x27;KitchenQual&#x27;</span>].fillna(all_data[<span class="string">&#x27;KitchenQual&#x27;</span>].mode()[<span class="number">0</span>])</span><br><span class="line">all_data[<span class="string">&#x27;Exterior1st&#x27;</span>] = all_data[<span class="string">&#x27;Exterior1st&#x27;</span>].fillna(all_data[<span class="string">&#x27;Exterior1st&#x27;</span>].mode()[<span class="number">0</span>])</span><br><span class="line">all_data[<span class="string">&#x27;Exterior2nd&#x27;</span>] = all_data[<span class="string">&#x27;Exterior2nd&#x27;</span>].fillna(all_data[<span class="string">&#x27;Exterior2nd&#x27;</span>].mode()[<span class="number">0</span>])</span><br><span class="line">all_data[<span class="string">&#x27;SaleType&#x27;</span>] = all_data[<span class="string">&#x27;SaleType&#x27;</span>].fillna(all_data[<span class="string">&#x27;SaleType&#x27;</span>].mode()[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<ul>
<li><code>Utilities</code>：这一项除了两个缺失值外只有训练集中有一个值是特例，也就是说这一个变量对预测没有任何影响，故删去。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_data = all_data.drop([<span class="string">&#x27;Utilities&#x27;</span>], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>Functional</code>：数据说明中有提到，空值代表<code>Typ</code>（典型）。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_data[<span class="string">&quot;Functional&quot;</span>] = all_data[<span class="string">&quot;Functional&quot;</span>].fillna(<span class="string">&quot;Typ&quot;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>MSSubClass</code>：缺失值可能意味着该样本的房屋没有建筑等级，用<code>None</code>来填充。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_data[<span class="string">&#x27;MSSubClass&#x27;</span>] = all_data[<span class="string">&#x27;MSSubClass&#x27;</span>].fillna(<span class="string">&quot;None&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>然后再检查一遍是否还遗漏了未补全的缺失值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 再次检查缺失值</span></span><br><span class="line">all_data_na = (all_data.isnull().<span class="built_in">sum</span>() / <span class="built_in">len</span>(all_data)) * <span class="number">100</span></span><br><span class="line">all_data_na = all_data_na.drop(all_data_na[all_data_na == <span class="number">0</span>].index).sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">missing_data = pd.DataFrame(&#123;<span class="string">&#x27;Missing Ratio&#x27;</span> :all_data_na&#125;)</span><br><span class="line">missing_data.head()</span><br></pre></td></tr></table></figure>

<h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><h3 id="数值型转换为标称型"><a href="#数值型转换为标称型" class="headerlink" title="数值型转换为标称型"></a>数值型转换为标称型</h3><p>诸如<code>MSSubClass</code>（住宅类型）、<code>OverallCond</code>（房屋总体质量）等变量，虽然它们的值是数字，但本质上属于标称型变量，需将其转化为字符串类型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">all_data[<span class="string">&#x27;MSSubClass&#x27;</span>] = all_data[<span class="string">&#x27;MSSubClass&#x27;</span>].apply(<span class="built_in">str</span>)</span><br><span class="line">all_data[<span class="string">&#x27;OverallCond&#x27;</span>] = all_data[<span class="string">&#x27;OverallCond&#x27;</span>].astype(<span class="built_in">str</span>)</span><br><span class="line">all_data[<span class="string">&#x27;YrSold&#x27;</span>] = all_data[<span class="string">&#x27;YrSold&#x27;</span>].astype(<span class="built_in">str</span>)</span><br><span class="line">all_data[<span class="string">&#x27;MoSold&#x27;</span>] = all_data[<span class="string">&#x27;MoSold&#x27;</span>].astype(<span class="built_in">str</span>)</span><br></pre></td></tr></table></figure>

<h3 id="定序型转换为数值型"><a href="#定序型转换为数值型" class="headerlink" title="定序型转换为数值型"></a>定序型转换为数值型</h3><p>诸如<code>FireplaceQu</code>（壁炉质量）、<code>BsmtQual</code>（地下室高度）、<code>GarageQual</code>（车库质量）等变量，虽然它们是字符串类型的标称型变量，但其隐含了顺序的信息（如质量的好坏、功能的多少），需要对其进行Label Encoding，使其转化为有序的数字。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">cols = (<span class="string">&#x27;FireplaceQu&#x27;</span>, <span class="string">&#x27;BsmtQual&#x27;</span>, <span class="string">&#x27;BsmtCond&#x27;</span>, <span class="string">&#x27;GarageQual&#x27;</span>, <span class="string">&#x27;GarageCond&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;ExterQual&#x27;</span>, <span class="string">&#x27;ExterCond&#x27;</span>,<span class="string">&#x27;HeatingQC&#x27;</span>, <span class="string">&#x27;PoolQC&#x27;</span>, <span class="string">&#x27;KitchenQual&#x27;</span>, <span class="string">&#x27;BsmtFinType1&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;BsmtFinType2&#x27;</span>, <span class="string">&#x27;Functional&#x27;</span>, <span class="string">&#x27;Fence&#x27;</span>, <span class="string">&#x27;BsmtExposure&#x27;</span>, <span class="string">&#x27;GarageFinish&#x27;</span>, <span class="string">&#x27;LandSlope&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;LotShape&#x27;</span>, <span class="string">&#x27;PavedDrive&#x27;</span>, <span class="string">&#x27;Street&#x27;</span>, <span class="string">&#x27;Alley&#x27;</span>, <span class="string">&#x27;CentralAir&#x27;</span>, <span class="string">&#x27;MSSubClass&#x27;</span>, <span class="string">&#x27;OverallCond&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;YrSold&#x27;</span>, <span class="string">&#x27;MoSold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> cols:</span><br><span class="line">    lbl = LabelEncoder()</span><br><span class="line">    lbl.fit(<span class="built_in">list</span>(all_data[c].values))</span><br><span class="line">    all_data[c] = lbl.transform(<span class="built_in">list</span>(all_data[c].values))</span><br></pre></td></tr></table></figure>

<h3 id="创造新变量"><a href="#创造新变量" class="headerlink" title="创造新变量"></a>创造新变量</h3><p>鉴于房屋面积在决定房价的各个变量中居于主导地位，原作者添加了一个新的变量<code>TotalSF</code>，它是房屋地下室、第一层和第二层面积的总和。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_data[<span class="string">&#x27;TotalSF&#x27;</span>] = all_data[<span class="string">&#x27;TotalBsmtSF&#x27;</span>] + all_data[<span class="string">&#x27;1stFlrSF&#x27;</span>] + all_data[<span class="string">&#x27;2ndFlrSF&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h3 id="正态化：box-cox变换"><a href="#正态化：box-cox变换" class="headerlink" title="正态化：box-cox变换"></a>正态化：box-cox变换</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 筛选出所有数值型的变量</span></span><br><span class="line">numeric_feats = all_data.dtypes[all_data.dtypes != <span class="string">&quot;object&quot;</span>].index</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查所有数值型变量的偏态</span></span><br><span class="line">skewed_feats = all_data[numeric_feats].apply(<span class="keyword">lambda</span> x: skew(x.dropna())).sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nSkew in numerical features: \n&quot;</span>)</span><br><span class="line">skewness = pd.DataFrame(&#123;<span class="string">&#x27;Skew&#x27;</span> :skewed_feats&#125;)</span><br><span class="line">skewness.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<p>使用box-cox变换来正态化呈现明显偏态的变量。关于box-cox变换，可以参考<a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.special.boxcox1p.html">scipy的官方文档</a>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">skewness = skewness[<span class="built_in">abs</span>(skewness) &gt; <span class="number">0.75</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;There are &#123;&#125; skewed numerical features to Box Cox transform&quot;</span>.<span class="built_in">format</span>(skewness.shape[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scipy.special <span class="keyword">import</span> boxcox1p</span><br><span class="line">skewed_features = skewness.index</span><br><span class="line">lam = <span class="number">0.15</span></span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> skewed_features:</span><br><span class="line">    all_data[feat] = boxcox1p(all_data[feat], lam)</span><br></pre></td></tr></table></figure>

<p><strong>输出</strong>：There are 59 skewed numerical features to Box Cox transform</p>
<h3 id="虚拟变量"><a href="#虚拟变量" class="headerlink" title="虚拟变量"></a>虚拟变量</h3><p>把所有离散型变量变成one-hot形式的变量。这一步可能会导致数据的变量数量大大增加。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_data = pd.get_dummies(all_data)</span><br><span class="line"><span class="built_in">print</span>(all_data.shape)</span><br></pre></td></tr></table></figure>

<p><strong>输出</strong>：(2917, 220)</p>
<p>以上完成了数据清洗的步骤，将合并后的数据集还原成训练集和测试集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train = all_data[:ntrain]</span><br><span class="line">test = all_data[ntrain:]</span><br></pre></td></tr></table></figure>

<h2 id="训练模型与测试"><a href="#训练模型与测试" class="headerlink" title="训练模型与测试"></a>训练模型与测试</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调包</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> ElasticNet, Lasso, BayesianRidge, LassoLarsIC <span class="comment">#线性回归模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor, GradientBoostingRegressor <span class="comment">#集成模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn.kernel_ridge <span class="keyword">import</span> KernelRidge <span class="comment">#核岭回归</span></span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> make_pipeline <span class="comment">#pipeline</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> RobustScaler <span class="comment">#标准化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin, RegressorMixin, clone <span class="comment">#自定义类的API</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, cross_val_score, train_test_split <span class="comment">#交叉验证</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error <span class="comment">#均方误差</span></span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb <span class="comment">#XGBoost</span></span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb <span class="comment">#lightGBM</span></span><br></pre></td></tr></table></figure>

<h3 id="定义模型评估方法"><a href="#定义模型评估方法" class="headerlink" title="定义模型评估方法"></a>定义模型评估方法</h3><ul>
<li>直接使用<code>cross_val_score</code>的参数<code>cv=5</code>没有将数据的顺序随机打乱，因此用了<code>KFold</code>方法，手动添加了<code>shuffle=True</code>，再用<code>get_n_splits</code>返回K折的折数。</li>
<li><code>random_state</code>为随机种子，保证每次得到的结果与原作者相同，该参数可以不加。</li>
<li>返回的<code>rmse</code>是模型在训练集上的均方根误差。由于Y已经对数转换过，因此实际上该值代表的是均方根误差的对数，即RMSLE。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 5折交叉验证</span></span><br><span class="line">n_folds = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rmsle_cv</span>(<span class="params">model</span>):</span></span><br><span class="line">    kf = KFold(n_folds, shuffle=<span class="literal">True</span>, random_state=<span class="number">42</span>).get_n_splits(train.values)</span><br><span class="line">    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=<span class="string">&quot;neg_mean_squared_error&quot;</span>, cv = kf))</span><br><span class="line">    <span class="keyword">return</span>(rmse)</span><br></pre></td></tr></table></figure>

<h3 id="基础模型"><a href="#基础模型" class="headerlink" title="基础模型"></a>基础模型</h3><p>原作者使用了常见的三种带正则化的线性回归模型和Kaggle比赛上大热的几种集成学习模型：GB、XGBoost和LightGBM。</p>
<ul>
<li><strong>Lasso回归</strong>：该算法对离群值敏感，因此需要加强鲁棒性。本例使用了<code>Robustscaler</code>这一标准化方法来缩放离群值。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lasso = make_pipeline(RobustScaler(), Lasso(alpha =<span class="number">0.0005</span>, random_state=<span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>弹性网络回归（Elastic Net）</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=<span class="number">0.0005</span>, l1_ratio=<span class="number">.9</span>, random_state=<span class="number">3</span>))</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>核岭回归（KRR）</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KRR = KernelRidge(alpha=<span class="number">0.6</span>, kernel=<span class="string">&#x27;polynomial&#x27;</span>, degree=<span class="number">2</span>, coef0=<span class="number">2.5</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>Gradient Boosting回归</strong>：采用了Huber loss，处理离群值时更加健壮。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">GBoost = GradientBoostingRegressor(n_estimators=<span class="number">3000</span>, learning_rate=<span class="number">0.05</span>,</span><br><span class="line">                                   max_depth=<span class="number">4</span>, max_features=<span class="string">&#x27;sqrt&#x27;</span>,</span><br><span class="line">                                   min_samples_leaf=<span class="number">15</span>, min_samples_split=<span class="number">10</span>,</span><br><span class="line">                                   loss=<span class="string">&#x27;huber&#x27;</span>, random_state =<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>XGBoost</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model_xgb = xgb.XGBRegressor(colsample_bytree=<span class="number">0.4603</span>, gamma=<span class="number">0.0468</span>,</span><br><span class="line">                             learning_rate=<span class="number">0.05</span>, max_depth=<span class="number">3</span>,</span><br><span class="line">                             min_child_weight=<span class="number">1.7817</span>, n_estimators=<span class="number">2200</span>,</span><br><span class="line">                             reg_alpha=<span class="number">0.4640</span>, reg_lambda=<span class="number">0.8571</span>,</span><br><span class="line">                             subsample=<span class="number">0.5213</span>, silent=<span class="number">1</span>,</span><br><span class="line">                             random_state =<span class="number">7</span>, nthread = -<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>LightGBM</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model_lgb = lgb.LGBMRegressor(objective=<span class="string">&#x27;regression&#x27;</span>,num_leaves=<span class="number">5</span>,</span><br><span class="line">                              learning_rate=<span class="number">0.05</span>, n_estimators=<span class="number">720</span>,</span><br><span class="line">                              max_bin = <span class="number">55</span>, bagging_fraction = <span class="number">0.8</span>,</span><br><span class="line">                              bagging_freq = <span class="number">5</span>, feature_fraction = <span class="number">0.2319</span>,</span><br><span class="line">                              feature_fraction_seed=<span class="number">9</span>, bagging_seed=<span class="number">9</span>,</span><br><span class="line">                              min_data_in_leaf =<span class="number">6</span>, min_sum_hessian_in_leaf = <span class="number">11</span>)</span><br></pre></td></tr></table></figure>

<p>用RMSLE评估各个基础模型在交叉验证集上的得分。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">score = rmsle_cv(lasso)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nLasso score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n&quot;</span>.<span class="built_in">format</span>(score.mean(), score.std()))</span><br></pre></td></tr></table></figure>

<p><strong>输出</strong>：Lasso score: 0.1115 (0.0074)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">score = rmsle_cv(ENet)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;ElasticNet score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n&quot;</span>.<span class="built_in">format</span>(score.mean(), score.std()))</span><br></pre></td></tr></table></figure>

<p><strong>输出</strong>：ElasticNet score: 0.1116 (0.0074)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">score = rmsle_cv(KRR)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Kernel Ridge score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n&quot;</span>.<span class="built_in">format</span>(score.mean(), score.std()))</span><br></pre></td></tr></table></figure>

<p><strong>输出</strong>：Kernel Ridge score: 0.1153 (0.0075)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">score = rmsle_cv(GBoost)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Gradient Boosting score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n&quot;</span>.<span class="built_in">format</span>(score.mean(), score.std()))</span><br></pre></td></tr></table></figure>

<p><strong>输出</strong>：Gradient Boosting score: 0.1177 (0.0080)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">score = rmsle_cv(model_xgb)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Xgboost score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n&quot;</span>.<span class="built_in">format</span>(score.mean(), score.std()))</span><br></pre></td></tr></table></figure>

<p><strong>输出</strong>：Xgboost score: 0.1151 (0.0069)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">score = rmsle_cv(model_lgb)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;LGBM score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n&quot;</span> .<span class="built_in">format</span>(score.mean(), score.std()))</span><br></pre></td></tr></table></figure>

<p><strong>输出</strong>：LGBM score: 0.1162 (0.0071)</p>
<h3 id="集成模型"><a href="#集成模型" class="headerlink" title="集成模型"></a>集成模型</h3><h4 id="最简单的集成模型：取各个基础模型的均值"><a href="#最简单的集成模型：取各个基础模型的均值" class="headerlink" title="最简单的集成模型：取各个基础模型的均值"></a>最简单的集成模型：取各个基础模型的均值</h4><p>新建一个类<code>AveragingModels</code>用于封装自定义的模型。<code>sklearn.base</code>中提供了所需继承的父类。</p>
<ul>
<li><code>BaseEstimator</code>：所有预测模型的基类，提供读写参数的方法（<code>__init__()</code>）。</li>
<li><code>RegressorMixin</code>：回归模型的Mixin类，提供返回回归模型$R^2$的方法（<code>predict()</code>）。</li>
<li><code>TransformerMixin</code>：提供拟合数据方法的Mixin类（<code>fit()</code>）。</li>
<li><code>clone</code>：复制一个具有相同参数的预测模型，不复制数据。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AveragingModels</span>(<span class="params">BaseEstimator, RegressorMixin, TransformerMixin</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, models</span>):</span></span><br><span class="line">        self.models = models</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        <span class="comment"># 克隆原始模型</span></span><br><span class="line">        self.models_ = [clone(x) <span class="keyword">for</span> x <span class="keyword">in</span> self.models]</span><br><span class="line">        <span class="comment"># 拟合克隆的模型</span></span><br><span class="line">        <span class="keyword">for</span> model <span class="keyword">in</span> self.models_:</span><br><span class="line">            model.fit(X, y)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用克隆的模型预测并取其平均值</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        predictions = np.column_stack([model.predict(X) \</span><br><span class="line">        <span class="keyword">for</span> model <span class="keyword">in</span> self.models_])</span><br><span class="line">        <span class="keyword">return</span> np.mean(predictions, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>用ENet、GBR、KRR和Lasso做一个均值集成模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">averaged_models = AveragingModels(models = (ENet, GBoost, KRR, lasso))</span><br><span class="line"></span><br><span class="line">score = rmsle_cv(averaged_models)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; Averaged base models score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n&quot;</span>.<span class="built_in">format</span>(score.mean(), score.std()))</span><br></pre></td></tr></table></figure>

<p><strong>输出</strong>：Averaged base models score: 0.1091 (0.0075)</p>
<p>可以看出，即便是最简单的均值集成模型也能取得比单一模型更好的效果。在此基础上尝试更加复杂的集成模型。</p>
<h4 id="进阶：Stacking集成模型"><a href="#进阶：Stacking集成模型" class="headerlink" title="进阶：Stacking集成模型"></a>进阶：Stacking集成模型</h4><p>Stacking模型的重点是在均值基础模型上添加一个元模型，并使用元模型进行最终预测。感兴趣的可以看一下这篇kernel：<a target="_blank" rel="noopener" href="https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python">Stacking集成模型入门</a>。</p>
<p>整个Stacking过程主要分为两层：</p>
<ul>
<li><p>第一层通常会采用多种不同的基础模型（称为初级学习器），并采用K折（这里假设K=5），即把原始训练数据集分成5份，则需要进行5次迭代，每次迭代在其中4份上训练每一个初级学习器，用剩下的1份测试。在经历5次迭代之后，在整个原始训练集上都获得了新的预测结果，将其合并，称为次级训练集；每次训练同时都会在整个原始测试集上进行拟合，得到的5个结果取平均值作为次级测试集。</p>
</li>
<li><p>将多个初级学习器得到的次级训练集合并作为输入，原Y作为输出，训练元模型，并用其拟合次级测试集，得到最终预测。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Stacking模型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StackingAveragedModels</span>(<span class="params">BaseEstimator, RegressorMixin, TransformerMixin</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, base_models, meta_model, n_folds=<span class="number">5</span></span>):</span></span><br><span class="line">        self.base_models = base_models</span><br><span class="line">        self.meta_model = meta_model</span><br><span class="line">        self.n_folds = n_folds</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        self.base_models_ = [<span class="built_in">list</span>() <span class="keyword">for</span> x <span class="keyword">in</span> self.base_models]</span><br><span class="line">        self.meta_model_ = clone(self.meta_model)</span><br><span class="line">        kfold = KFold(n_splits=self.n_folds, shuffle=<span class="literal">True</span>, random_state=<span class="number">156</span>)</span><br><span class="line">        out_of_fold_predictions = np.zeros((X.shape[<span class="number">0</span>], <span class="built_in">len</span>(self.base_models)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, model <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.base_models):</span><br><span class="line">            <span class="keyword">for</span> train_index, holdout_index <span class="keyword">in</span> kfold.split(X, y):</span><br><span class="line">                instance = clone(model)</span><br><span class="line">                self.base_models_[i].append(instance)</span><br><span class="line">                instance.fit(X[train_index], y[train_index])</span><br><span class="line">                y_pred = instance.predict(X[holdout_index])</span><br><span class="line">                out_of_fold_predictions[holdout_index, i] = y_pred</span><br><span class="line"></span><br><span class="line">        self.meta_model_.fit(out_of_fold_predictions, y)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        meta_features = np.column_stack([</span><br><span class="line">            np.column_stack([model.predict(X) <span class="keyword">for</span> model <span class="keyword">in</span> base_models]).mean(axis=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">for</span> base_models <span class="keyword">in</span> self.base_models_ ])</span><br><span class="line">        <span class="keyword">return</span> self.meta_model_.predict(meta_features)</span><br></pre></td></tr></table></figure>

<p>使用Enet、KRR和Gboost作为初级学习器，Lasso作为元学习器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR), meta_model = lasso)</span><br><span class="line"></span><br><span class="line">score = rmsle_cv(stacked_averaged_models)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Stacking Averaged models score: &#123;:.4f&#125; (&#123;:.4f&#125;)&quot;</span>.<span class="built_in">format</span>(score.mean(), score.std()))</span><br></pre></td></tr></table></figure>

<p><strong>输出</strong>：Stacking Averaged models score: 0.1085 (0.0074)</p>
<p>从RMSLE得分上来看，运用Stacking集成之后得到了更好的验证集精度。</p>
<h4 id="集成Stacking、XGBoost和LightGBM"><a href="#集成Stacking、XGBoost和LightGBM" class="headerlink" title="集成Stacking、XGBoost和LightGBM"></a>集成Stacking、XGBoost和LightGBM</h4><p>首先定义RMSLE评分函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rmsle</span>(<span class="params">y, y_pred</span>):</span></span><br><span class="line">    <span class="keyword">return</span> np.sqrt(mean_squared_error(y, y_pred))</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>Stacking</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">stacked_averaged_models.fit(train.values, y_train)</span><br><span class="line">stacked_train_pred = stacked_averaged_models.predict(train.values)</span><br><span class="line">stacked_pred = np.expm1(stacked_averaged_models.predict(test.values))</span><br><span class="line"><span class="built_in">print</span>(rmsle(y_train, stacked_train_pred))</span><br></pre></td></tr></table></figure>

<p><strong>输出</strong>：0.07815719379164626</p>
<ul>
<li><strong>XGBoost</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model_xgb.fit(train, y_train)</span><br><span class="line">xgb_train_pred = model_xgb.predict(train)</span><br><span class="line">xgb_pred = np.expm1(model_xgb.predict(test))</span><br><span class="line"><span class="built_in">print</span>(rmsle(y_train, xgb_train_pred))</span><br></pre></td></tr></table></figure>

<p><strong>输出</strong>：0.07879894799249872</p>
<ul>
<li><strong>LightGBM</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model_lgb.fit(train, y_train)</span><br><span class="line">lgb_train_pred = model_lgb.predict(train)</span><br><span class="line">lgb_pred = np.expm1(model_lgb.predict(test.values))</span><br><span class="line"><span class="built_in">print</span>(rmsle(y_train, lgb_train_pred))</span><br></pre></td></tr></table></figure>

<p><strong>输出</strong>：0.07307464036005418</p>
<p>把三个集成学习模型加权平均得到最终预测结果。</p>
<p>关于如何确定权重，原作者没有给出具体的方法，推测是根据RMSLE的高低来分配权重。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;RMSLE score on train data:&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(rmsle(y_train,stacked_train_pred*<span class="number">0.70</span> +</span><br><span class="line">               xgb_train_pred*<span class="number">0.15</span> + lgb_train_pred*<span class="number">0.15</span> ))</span><br></pre></td></tr></table></figure>

<p><strong>输出</strong>：RMSLE score on train data: 0.07543604303996428</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ensemble = stacked_pred*<span class="number">0.70</span> + xgb_pred*<span class="number">0.15</span> + lgb_pred*<span class="number">0.15</span></span><br></pre></td></tr></table></figure>

<p>在测试集上运用最终的加权平均，得到的结果输出csv文件后可以提交。原作者最终RMSLE得分为0.11420，截至2017年7月2日排名前4%。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本kernel的以下几点值得学习借鉴：</p>
<ul>
<li>仔细处理缺失值。</li>
<li>按照实际情况增加了新的变量，转化了一些数值型或标称型变量，以及虚拟化变量。</li>
<li>对偏态分布的变量使用box-cox变换而不是log变换。</li>
<li>运用了Stacking方法，它是Kaggle上取得好名次的一大利器。</li>
</ul>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">首页</a></li>
         
          <li><a href="/about/">关于</a></li>
         
          <li><a href="/archives/">归档</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="toc-number">1.</span> <span class="toc-text">导入数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">2.</span> <span class="toc-text">数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A6%BB%E7%BE%A4%E5%80%BC"><span class="toc-number">2.1.</span> <span class="toc-text">离群值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87%E5%8F%98%E9%87%8F"><span class="toc-number">2.2.</span> <span class="toc-text">目标变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E6%80%A7"><span class="toc-number">2.3.</span> <span class="toc-text">相关性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%BA%E5%A4%B1%E5%80%BC"><span class="toc-number">2.4.</span> <span class="toc-text">缺失值</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="toc-number">3.</span> <span class="toc-text">特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E5%80%BC%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BA%E6%A0%87%E7%A7%B0%E5%9E%8B"><span class="toc-number">3.1.</span> <span class="toc-text">数值型转换为标称型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E5%BA%8F%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BA%E6%95%B0%E5%80%BC%E5%9E%8B"><span class="toc-number">3.2.</span> <span class="toc-text">定序型转换为数值型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E9%80%A0%E6%96%B0%E5%8F%98%E9%87%8F"><span class="toc-number">3.3.</span> <span class="toc-text">创造新变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E6%80%81%E5%8C%96%EF%BC%9Abox-cox%E5%8F%98%E6%8D%A2"><span class="toc-number">3.4.</span> <span class="toc-text">正态化：box-cox变换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E5%8F%98%E9%87%8F"><span class="toc-number">3.5.</span> <span class="toc-text">虚拟变量</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%B5%8B%E8%AF%95"><span class="toc-number">4.</span> <span class="toc-text">训练模型与测试</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95"><span class="toc-number">4.1.</span> <span class="toc-text">定义模型评估方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.2.</span> <span class="toc-text">基础模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E6%88%90%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.3.</span> <span class="toc-text">集成模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E9%9B%86%E6%88%90%E6%A8%A1%E5%9E%8B%EF%BC%9A%E5%8F%96%E5%90%84%E4%B8%AA%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9D%87%E5%80%BC"><span class="toc-number">4.3.1.</span> <span class="toc-text">最简单的集成模型：取各个基础模型的均值</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9B%E9%98%B6%EF%BC%9AStacking%E9%9B%86%E6%88%90%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.3.2.</span> <span class="toc-text">进阶：Stacking集成模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E6%88%90Stacking%E3%80%81XGBoost%E5%92%8CLightGBM"><span class="toc-number">4.3.3.</span> <span class="toc-text">集成Stacking、XGBoost和LightGBM</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">5.</span> <span class="toc-text">总结</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://ster.im/kaggle_03/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://ster.im/kaggle_03/&text=Kaggle机器学习实战（3）——房价预测（下）"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://ster.im/kaggle_03/&title=Kaggle机器学习实战（3）——房价预测（下）"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://ster.im/kaggle_03/&is_video=false&description=Kaggle机器学习实战（3）——房价预测（下）"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Kaggle机器学习实战（3）——房价预测（下）&body=Check out this article: https://ster.im/kaggle_03/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://ster.im/kaggle_03/&title=Kaggle机器学习实战（3）——房价预测（下）"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://ster.im/kaggle_03/&title=Kaggle机器学习实战（3）——房价预测（下）"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://ster.im/kaggle_03/&title=Kaggle机器学习实战（3）——房价预测（下）"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://ster.im/kaggle_03/&title=Kaggle机器学习实战（3）——房价预测（下）"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://ster.im/kaggle_03/&name=Kaggle机器学习实战（3）——房价预测（下）&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://ster.im/kaggle_03/&t=Kaggle机器学习实战（3）——房价预测（下）"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> 菜单</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> 目录</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> 分享</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> 返回顶部</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2012-2021
    Rarit7
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">首页</a></li>
         
          <li><a href="/about/">关于</a></li>
         
          <li><a href="/archives/">归档</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdn.bootcdn.net/ajax/libs/font-awesome/5.15.3/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->
 
  <script src="https://cdn.bootcdn.net/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script> 




<!-- clipboard -->

  
    <script src="https://cdn.bootcdn.net/ajax/libs/clipboard.js/2.0.8/clipboard.min.js" crossorigin="anonymous"></script> 
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"复制到粘贴板!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "复制成功!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Umami Analytics -->

<!-- Disqus Comments -->


</body>
</html>
